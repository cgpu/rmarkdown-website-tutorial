---
#title: "fastQsee: A tutorial on how to use Docker containers on the [Deploit platform](https://lifebit.page.link/deploit) to quickly generate a plot-ful FastQC report"
#date: ""
#author:
#- name: "Christina Chatzipantsiou"
#  email: "chatzipantsiou@gmail.com"
output: 
  html_document:
    toc: true
    toc_float: true  
    code_folding: hide
    code_download: true
    theme: cerulean  
    highlight: kate          # specifies the syntax highlighting style
---
<br><br>


# Overview

<br>

## Why do I need a FastQC report? 

The analysis journey of NGS generated FASTQ files should always start, as with any other data analysis task, with a robust __E__ xploratory __D__ ata __A__ nalysis (__EDA__) bout. 

<br><br>
<p style="text-align:center;">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/keep-calm-generator-twitter-cover-perform-eda.jpg?raw=true" style="width: 90%; height: 90%">
</p>
<br><br>

The <a href="https://lifebit.page.link/FastQC_Official_Page"  target="_blank">FastQC tool</b></a> (Andrews S. et al, 2010), facilitates this task by providing a plot-ful html report, with key metrics for read quality. 

<p style="text-align:center;">
<b>
<font size="3" color="black">FastQC quality assesment plots</font>
</b>

<br><br>

```{r}
list_of_img = c("https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_base_sequence_quality.png?raw=true",
                "https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_sequence_content.png?raw=true",
                "https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_sequence_quality_scores.png?raw=true",
                "https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_tile_sequence_quality.png?raw=true"
                )
slickR::slickR(obj     = list_of_img,
               padding = "10" ,
               width   = '70%',
               height  = 300
)
```

<br><br>
 
If not familiar with how to interpret the plots, you can start by taking a look at the <font size="2" color="green"><b>good</b></font> and <font size="2" color="red"><b>bad</b></font> quality sequencing data examples that are available in the <a href="https://lifebit.page.link/FastQC_Official_Page" target="_blank"><b>FastQC tool official webpage</b></a>.

There is also a really great presentation on _"RNA-seq quality control and pre-processing"_  by  <a href="https://lifebit.page.link/mikaelhusstwitter" target="_blank"><b>Mikael Huss</b></a> you can check out <a href="https://lifebit.page.link/mikaelhussRNAseq_quality" target="_blank"><b>here</b></a>. <br>

<br><br>
<p style="text-align:center;">
<a href="https://lifebit.page.link/mikaelhussRNAseq_quality"  target="_blank">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/RNAseq_quality_presentation.PNG?raw=true" style="width: 75%; height: 75%">
</a>
</p>
<br><br>


## What resources do I need to generate a __FastQC report__ on the Deploit platform? (spoiler hint: links!)
In this tutorial, we will bring all the required resources to generate a FastQC report on the __Deploit__ platform. For the most part the resources we will need can be provided in the form of __links__, that point to the following four fundamental ingredients of any data analysis pipeline:


<br><br>

### i) DATA <br>
The main ingredient. For this example we will use a ```FASTQ.gz``` file from the 1000genomes project.  We only need the __url__ that points to the file, hosted in the an EMBL-EBI FTP server. You can find the one we selected in the following link:<br>
<a href="https://lifebit.page.link/1000fastq" target="_blank"><b><code>ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/SRR062634.filt.fastq.gz></code></b></a>

<br>(link to parent repo)

<br>

### ii) CODE
The instructions, the recipe for the transformations that will be performed on our raw data. The FastQC tool takes as input uncompressed FASTQ format data. So we need code for __two main tasks__ to obtain the FastQC report. 

<br>

#### TASK 1: __Download__, __uncompress__ and _(optional but handy)_ __rename__ the fastq.gz file <br>
We will use the following ```>_ bash``` command to do exactly that:

* ```wget```: fetches from FTP server and download
* ```gunzip```: uncompresses .gz file 
* ```>```: renames

```
wget -O - https://lifebit.page.link/ftp_SRR062634_fastq_gz | gunzip -c > SRR062634.fastq 
```
For a more detailed breakdown of the command powered by Ubuntu's manpage repository, you can check <a href="https://lifebit.page.link/ExplainShell_fastQsee" target="_blank"><b>ExplainShell.com</b></a>. 
<br>
<br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/ExplainShell.gif?raw=true">
<br>
<br>
Feel free to swap the shortened ```https://lifebit.page.link/ftp_SRR062634_fastq_gz``` with the original ```ftp``` link provided above. 
The output of this command will be the uncompressed FASTQ file named ```SRR062634.fastq``` .

<br>

#### TASK 2: Run the FastQC tool with the uncompressed file as input to generate the FASTQ report.

For this we will use one of the pipelines already available in the __```PIPELINES > PUBLIC PIPELINES & TOOLS```__ section on the Deploit platform. The only input required for the report is the uncompressed FASTQ file we acquired from the previous step. 

<br>


### iii) OS & TOOLS 
The environment and tools that will facilitate the transformation of our data.<br>

We will obviously use __Docker__ , the __FastQC__ tool and its dependencies (eg. a suitable __J__ ava __R__ untime __E__ nvironment). However, __no installation is required__ on your machine because everything can be available on the <b><a href="https://lifebit.page.link/deploit" target="_blank">Deploit platform</b></a>, installation free. Docker containers will serve as our software microenvironments that will host each task of the workflow.

<br>

#### TASK 1: Port Docker container from Docker Hub to Deploit
For the first task mentioned above, to retrieve and uncompress the fastq.gz file, we will port a Docker container with a lightweight Linux distribution (we only need ```>_bash``` for `wget` and `gunzip`) from Docker Hub by providing the link to the respective repository. You can find the docker container we have chosen (with `Alpine` Linux) in the following link:<br>

<a href="https://hub.docker.com/r/bashell/alpine-bash" target="_blank"><b>https://hub.docker.com/r/frolvlad/alpine-bash</b></a>. <br>

We will use this Docker container for our combo ```wget | gunzip >``` command and deploy the job over cloud from the Deploit platform. The uncompressed file will be available in the ```DATA > JOB RESULTS``` section in the platform and available to be used as input in other pipelines.

<br>

#### TASK 2: Use the __FastQC__ tool, already available in the library of curated pipelines on Deploit

All we need for this is to select the `fastqc` pipeline from the library of curated pipelines available on the Deploit platform. As input, we will use the output file from the previous step, the uncompressed FASTQ file. The FASTQ file can be accessed in the ```DATA > JOB RESULTS``` section in the platform.

<br>

### iv) RESOURCES

Power! To spin all these up and generate our results. 

Deploit brings all __four__ required resources in one place. Deploit orchestrates the deployment of your jobs over cloud. If you don't have a cloud account yet, you can still try the platform. Upon registration, we provide you with a Lifebit cloud account with preloaded credits, so that you run your first analyses <a href="https://lifebit.page.link/lifebit-deploit" target="_blank"><img src="https://img.shields.io/badge/powered%20by-Deploit-blue.svg" ></a>. If you want to have access to your own resources (data, credits) you can link your own cloud account. 

<br>

## Why not install everything I need and run FastQC on my machine instead? 

In principle, you could actually easily install the dependencies for running FastQC on your own machine. But this tutorial is more about learning how to use Deploit to easily combine resources (code from GitHub, containers from Docker Hub) to assemble multi-step bioinformatics workflows. This ```fastQsee``` pipeline will serve as our dummy example to go through the steps.  <a href="https://lifebit.page.link/lifebit-deploit" target="_blank"><b>Deploit</b></a> enables you to structure your workflows as an assembly of individual, self contained units of computation (```jobs```), by bringing all the required resources to run an analysis (data, code, os & tools, computational resources) in one place. Each step in a bioinformatics workflow, will most likely utilize different tools and have different dependencies. But why not install all the tools on one machine, and run everything there, right? Well, for starters, dependencies!

<br><br>
<p style="text-align:center;">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/dependencies_everywhere.jpg?raw=true">
</p>
<br><br>

We all know that it's a hustle to make all the tools play nice together. There are several reasons why bioinformaticians have started joining developers and data scientists, and are slowly abandoning the monolithic, all-in-one place analysis environment approach and shifting towards more robust, modular and portable environment solutions. While virtualization and <a href="https://lifebit.page.link/brief_history_of_containers" target="_blank"><b>containers have been around for quite some time</b></a>, Docker has really revolutionized the way we work the past few years. In a bioinformatics workflow, each process can utilize a different container as an execution microenvironment, with a main focus on preventing dependencies conflicts and ensuring reproducibility.

<br>

This __modularity__ also unlocks many cool features as a positive side effect: <br>
<br>1) __Portability__ : Installation (and hustle!) free run on any another machine
<br>2) __Cloudability__ : Easily deploy <b><a href="https://lifebit.page.link/thereisnocloud" target="_blank">on cloud</a></b>
<br>3) __Reproducibility__ : Allow for someone else to run the shame pipeline
<br>4) __Frictionless Retouching:__ Allows for easily removing, adding or retouching individual processes without affecting the rest
<br>5) __Isolation of Dependencies:__ Conflicting dependencies are isolated
<br>6) __Same tool, different tool version__: Ability to use the same tool, but a different version of it in different processes if needed (legacy code in bioinformatics tools anyone?)

<br><br>
