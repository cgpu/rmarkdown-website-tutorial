---
title: "fastQsee: A tutorial on how to use Docker containers on the [Deploit platform](https://lifebit.page.link/deploit) to quickly generate a plot-ful FastQC report"
date: ""
#author:
#- name: "Christina Chatzipantsiou"
#  email: "chatzipantsiou@gmail.com"
output: 
  html_document:
    toc: true
    toc_float: true  
    code_folding: hide
    code_download: true
    theme: cerulean  
                             # many options for theme, this one is my favorite.
    highlight: kate          # specifies the syntax highlighting style
---
<br><br>

![](https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/docker_x_deploit_gif_blogpost_header.gif?raw=true)

<br><br>

# TL;DR

<br>

## Why call it 'fastQsee' though ðŸ¤”?

Well, because you will get to see ðŸ‘€ a FastQC report of your FASTQ file very fast! Installation-less and quick, made possible by a little container magic from Docker and powered by Deploit.

<br>


## What will I learn?

This tutorial is a primer, on how to go modular and use Docker `r emo::ji("whale")` containers for your bioinformatics analysis tasks. More specifically, we will learn how to use the <a href="https://lifebit.page.link/deploit"  target="_blank"><b>Deploit platform</b></a> to assemble and deploy on cloud a reproducible and sharable bioinformatics workflow. <br>

We will assemble the following resources into a workflow on the __Deploit__ platform: <br>

* `r emo::ji("whale")` a __Docker container__, from DockerHub 
* `r emo::ji("rocket")` a __curated pipeline__, available on the __Deploit__ platform
* `r emo::ji("document")` a 1000genomes project __```fastq.gz```__ file, fetched from an EMBL-EBI FTP site

<br>

## Last things first: What results will I get from the FastQC tool on Deploit?

After completing this mini workflow on the Deploit platform, you will have:<br><br> 
__1) a plot-full FastQC html report__, <br>
with key metrics to assess the quality of your FASTQ file <br>

__2) sharable links to your ```Job Page```__ s ,<br> 
with interactive plots and information about the resources and the results.

You can access the  ```Jobs Pages``` from the sharable urls we created for this example: <br>

* for retrieving the 1000genomes fastq.gz file : `r emo::ji('link')` <a href="https://lifebit.page.link/wgetGunzipper__sharable_page"  target="_blank"><code>wgetGunzipper</code></b></a> <br>
* for generating the FastQC html report: `r emo::ji('link')` <a href="https://lifebit.page.link/Job_Page_sharable_fastQsee"  target="_blank"><code>fastQsee</code></b></a><br>

and take a look at what a ```Job Page```  looks like below:

<br><br>
<a href="https://lifebit.page.link/lifebit-deploit" target="_blank"><img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/overview_of_job_page.gif?raw=true" ></a>
<br><br>

Also, you will have the sharable link for the Deploit page job, where you can find the html file of this tutorial (and also the rmarkdown file that created it!). Check below:

<br><br>
<p><iframe src="https://lifebit.page.link/fastQsee_Job_Page" width="100%" height="600"></iframe></p>
<br><br>

<br><br>
<a href="https://lifebit.page.link/fastQsee_Job_Page" target="_blank">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/download_fastqsee_from_deploit.gif?raw=true">
</a>
<br><br>

You can then download them, and you will have a tutorial to guide you on assembling and running reproducible bioinformatics workflows on the Deploit platfom. Now, let's move on with the step by step guide on how to run the FatsQC on Deploit. 

<br>

# Overview

<br>

## Why do I need a FastQC report? 

The analysis journey of NGS generated FASTQ files should always start, as with any other data analysis task, with a robust __E__ xploratory __D__ ata __A__ nalysis (__EDA__) bout. 

<br><br>
<p style="text-align:center;">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/keep-calm-generator-twitter-cover-perform-eda.jpg?raw=true" style="width: 90%; height: 90%">
</p>
<br><br>

The <a href="https://lifebit.page.link/FastQC_Official_Page"  target="_blank">FastQC tool</b></a> (Andrews S. et al, 2010), facilitates this task by providing a plot-ful html report, with key metrics for read quality. 

<p style="text-align:center;">
<b>
<font size="3" color="black">FastQC quality assesment plots</font>
</b>

<br><br>

```{r}
list_of_img = c("https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_base_sequence_quality.png?raw=true",
                "https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_sequence_content.png?raw=true",
                "https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_sequence_quality_scores.png?raw=true",
                "https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/per_tile_sequence_quality.png?raw=true"
                )
slickR::slickR(obj     = list_of_img,
               padding = "10" ,
               width   = '70%',
               height  = 300
)
```

<br><br>
 
If not familiar with how to interpret the plots, you can start by taking a look at the <font size="2" color="green"><b>good</b></font> and <font size="2" color="red"><b>bad</b></font> quality sequencing data examples that are available in the <a href="https://lifebit.page.link/FastQC_Official_Page" target="_blank"><b>FastQC tool official webpage</b></a>.

There is also a really great presentation on _"RNA-seq quality control and pre-processing"_  by  <a href="https://lifebit.page.link/mikaelhusstwitter" target="_blank"><b>Mikael Huss</b></a> you can check out <a href="https://lifebit.page.link/mikaelhussRNAseq_quality" target="_blank"><b>here</b></a>. <br>

<br><br>
<p style="text-align:center;">
<a href="https://lifebit.page.link/mikaelhussRNAseq_quality"  target="_blank">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/RNAseq_quality_presentation.PNG?raw=true" style="width: 75%; height: 75%">
</a>
</p>
<br><br>


## What resources do I need to generate a __FastQC report__ on the Deploit platform? (spoiler hint: links!)
In this tutorial, we will bring all the required resources to generate a FastQC report on the __Deploit__ platform. For the most part the resources we will need can be provided in the form of __links__, that point to the following four fundamental ingredients of any data analysis pipeline:


<br><br>

### i) DATA <br>
The main ingredient. For this example we will use a ```FASTQ.gz``` file from the 1000genomes project.  We only need the __url__ that points to the file, hosted in the an EMBL-EBI FTP server. You can find the one we selected in the following link:<br>
<a href="https://lifebit.page.link/1000fastq" target="_blank"><b><code>ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/SRR062634.filt.fastq.gz></code></b></a>

<br>(link to parent repo)

<br>

### ii) CODE
The instructions, the recipe for the transformations that will be performed on our raw data. The FastQC tool takes as input uncompressed FASTQ format data. So we need code for __two main tasks__ to obtain the FastQC report. 

<br>

#### TASK 1: __Download__, __uncompress__ and _(optional but handy)_ __rename__ the fastq.gz file <br>
We will use the following ```>_ bash``` command to do exactly that:

* ```wget```: fetches from FTP server and download
* ```gunzip```: uncompresses .gz file 
* ```>```: renames

```
wget -O - https://lifebit.page.link/ftp_SRR062634_fastq_gz | gunzip -c > SRR062634.fastq 
```
For a more detailed breakdown of the command powered by Ubuntu's manpage repository, you can check <a href="https://lifebit.page.link/ExplainShell_fastQsee" target="_blank"><b>ExplainShell.com</b></a>. 
<br>
<br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/ExplainShell.gif?raw=true">
<br>
<br>
Feel free to swap the shortened ```https://lifebit.page.link/ftp_SRR062634_fastq_gz``` with the original ```ftp``` link provided above. 
The output of this command will be the uncompressed FASTQ file named ```SRR062634.fastq``` .

<br>

#### TASK 2: Run the FastQC tool with the uncompressed file as input to generate the FASTQ report.

For this we will use one of the pipelines already available in the __```PIPELINES > PUBLIC PIPELINES & TOOLS```__ section on the Deploit platform. The only input required for the report is the uncompressed FASTQ file we acquired from the previous step. 

<br>


### iii) OS & TOOLS 
The environment and tools that will facilitate the transformation of our data.<br>

We will obviously use __Docker__ , the __FastQC__ tool and its dependencies (eg. a suitable __J__ ava __R__ untime __E__ nvironment). However, __no installation is required__ on your machine because everything can be available on the <b><a href="https://lifebit.page.link/deploit" target="_blank">Deploit platform</b></a>, installation free. Docker containers will serve as our software microenvironments that will host each task of the workflow.

<br>

#### TASK 1: Port Docker container from Docker Hub to Deploit
For the first task mentioned above, to retrieve and uncompress the fastq.gz file, we will port a Docker container with a lightweight Linux distribution (we only need ```>_bash``` for `wget` and `gunzip`) from Docker Hub by providing the link to the respective repository. You can find the docker container we have chosen (with `Alpine` Linux) in the following link:<br>

<a href="https://hub.docker.com/r/bashell/alpine-bash" target="_blank"><b>https://hub.docker.com/r/frolvlad/alpine-bash</b></a>. <br>

We will use this Docker container for our combo ```wget | gunzip >``` command and deploy the job over cloud from the Deploit platform. The uncompressed file will be available in the ```DATA > JOB RESULTS``` section in the platform and available to be used as input in other pipelines.

<br>

#### TASK 2: Use the __FastQC__ tool, already available in the library of curated pipelines on Deploit

All we need for this is to select the `fastqc` pipeline from the library of curated pipelines available on the Deploit platform. As input, we will use the output file from the previous step, the uncompressed FASTQ file. The FASTQ file can be accessed in the ```DATA > JOB RESULTS``` section in the platform.

<br>

### iv) RESOURCES

Power! To spin all these up and generate our results. 

Deploit brings all __four__ required resources in one place. Deploit orchestrates the deployment of your jobs over cloud. If you don't have a cloud account yet, you can still try the platform. Upon registration, we provide you with a Lifebit cloud account with preloaded credits, so that you run your first analyses <a href="https://lifebit.page.link/lifebit-deploit" target="_blank"><img src="https://img.shields.io/badge/powered%20by-Deploit-blue.svg" ></a>. If you want to have access to your own resources (data, credits) you can link your own cloud account. 

<br>

## Why not install everything I need and run FastQC on my machine instead? 

In principle, you could actually easily install the dependencies for running FastQC on your own machine. But this tutorial is more about learning how to use Deploit to easily combine resources (code from GitHub, containers from Docker Hub) to assemble multi-step bioinformatics workflows. This ```fastQsee``` pipeline will serve as our dummy example to go through the steps.  <a href="https://lifebit.page.link/lifebit-deploit" target="_blank"><b>Deploit</b></a> enables you to structure your workflows as an assembly of individual, self contained units of computation (```jobs```), by bringing all the required resources to run an analysis (data, code, os & tools, computational resources) in one place. Each step in a bioinformatics workflow, will most likely utilize different tools and have different dependencies. But why not install all the tools on one machine, and run everything there, right? Well, for starters, dependencies!

<br><br>
<p style="text-align:center;">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/dependencies_everywhere.jpg?raw=true">
</p>
<br><br>

We all know that it's a hustle to make all the tools play nice together. There are several reasons why bioinformaticians have started joining developers and data scientists, and are slowly abandoning the monolithic, all-in-one place analysis environment approach and shifting towards more robust, modular and portable environment solutions. While virtualization and <a href="https://lifebit.page.link/brief_history_of_containers" target="_blank"><b>containers have been around for quite some time</b></a>, Docker has really revolutionized the way we work the past few years. In a bioinformatics workflow, each process can utilize a different container as an execution microenvironment, with a main focus on preventing dependencies conflicts and ensuring reproducibility.

<br>

This __modularity__ also unlocks many cool features as a positive side effect: <br>
<br>1) __Portability__ : Installation (and hustle!) free run on any another machine
<br>2) __Cloudability__ : Easily deploy <b><a href="https://lifebit.page.link/thereisnocloud" target="_blank">on cloud</a></b>
<br>3) __Reproducibility__ : Allow for someone else to run the shame pipeline
<br>4) __Frictionless Retouching:__ Allows for easily removing, adding or retouching individual processes without affecting the rest
<br>5) __Isolation of Dependencies:__ Conflicting dependencies are isolated
<br>6) __Same tool, different tool version__: Ability to use the same tool, but a different version of it in different processes if needed (legacy code in bioinformatics tools anyone?)

<br><br>

# Step-By-Step Tutorial: Deploit in action (aka in gifs!)

Now that we have an overview of how Deploit brings your resources in one place, and we have found what resources we will need, time to go back to the ```fastQsee``` tutorial to generate the FastQC report. 

<br>

All the resources that we will need can be summarized in the following table:

<br>

__What__ | __Where__               
:-----------------|:-------------
DATA              | <a href="https://lifebit.page.link/1000fastq" target="_blank"><b>SRR062634.fastq.gz (1000genomes example file)</b></a>
CODE              | ```wget -O - https://lifebit.page.link/ftp_SRR062634_fastq_gz | gunzip -c > SRR062634.fastq``` 
OS/TOOLS          | <a href="https://lifebit.page.link/alpine-bash_Docker" target="_blank"><b>frolvlad/alpine-bash</b></a> & <a href="https://lifebit.page.link/alpine-bash_Docker" target="_blank"><b>lifebitai/fastqc</b></a> Docker containers
RESOURCES         | Lifebit Cloud <a href="https://lifebit.page.link/login_to_your_Deploit_account" target="_blank"><b>(provided with registration)</b></a>

<br>

Let's head over to the Deploit platform to generate the FastQC report step-by-step.

<br>


## STEP 0: Create a ```Project``` for your analysis tasks

For generating the ```FastQC``` report, we will deploy two jobs:

<br>

__1)__ One for retrieving the file<br>
__2)__ One for running the FastQC tool. 

<br>

It is advised to create a ```Project``` to host the individual analyses (aka jobs) of a workflow. Think of the ```Project``` entity in the Deploit platform, as your parent directory for the project. There, you will have access not only to the __data__ and __code__, but also to all the __```Jobs```__ that have been run. You will have the ability to revisit, clone and deploy again the same jobs very easily. 

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/JobMonitor_Reults_CloneJob.gif?raw=true">
<br><br>


<a href="https://lifebit.page.link/login_to_your_Deploit_account" target="_blank"><b>Log in to your Deploit account</b></a> and access the ```Projects``` section from the light bulb icon `r emo::ji("light_bulb")`  on the left of your screen. Click on the green ```New``` button on the right, and provide a ```Name``` and ```Description``` for your new Project.

<br>
We set up the ```Project``` for this example by filling in: 
<br>

* ```Name       ```: __"fastQsee"__
* ```Description```: __"Quickly generate a FastQC report"__

<br>

You can find an overview of how these steps look on Deploit below: 
<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/create_project.gif?raw=true">

<br><br>

## STEP 1: Port the <a href="https://lifebit.page.link/alpine-bash_Docker" target="_blank"><b>frolvlad/alpine-bash</b></a> Docker container to Deploit

After you log in to Deploit, find the __```Pipelines```__ section from the navigation bar on the left of your screen. We will create a new pipeline in the ```Pipelines > My Pipelines & Tools``` section. 

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/pipelines_my_pipelines_and_tools.gif?raw=true">
<br><br>

This is how we will port the <a href="https://lifebit.page.link/alpine-bash_Docker" target="_blank"><b>frolvlad/alpine-bash</b></a> Docker container to Deploit, so that we can it use it for retrieving the ```fastq.gz``` file. Have the link to the Docker repository ready for copy+pasting <br>
URL to Docker Hub: <a href="https://lifebit.page.link/alpine-bash_Docker" target="_blank"><b>hub.docker.com/r/frolvlad/alpine-bash</b></a>
<br>

Have the link to the Docker repository ready for copy+pasting and then go ahead and click the green ```New``` button on the right.

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/dockerhub_url.gif?raw=true">
<br><br>

As shown above, you will be prompted to select __"Where are you porting your pipeline from?"__. Click on the Docker whale and then click on ```Select``` to proceed. Continue by filling in the required fields to port the container. You can have a look at how we set this up below as an example: 

<br><br>

* ```Docker hub URL```: https://hub.docker.com/r/frolvlad/alpine-bash
* ```Name``` : __"wgetGunzipper"__
* ```Default command```: _(leave this blank)_
* ```Description```: __"A lightweight Linux distro for wget/gunzip__

<br><br>

The ```Default command``` is handy for saving time, but for now we will leave this blank so that we can use the command field as a terminal. You can see an overview of the process described above in the following gif:

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/create_new_pipeline.gif?raw=true">
<br><br><br>


## STEP 2: Use the newly created pipeline to retrieve and uncompress the ```fastq.gz``` file on Deploit

Time to use our newly created pipeline, and utilize the Docker container that we ported. We will use the command field on Deploit as a terminal, and the Docker container as our operating system to download and decompress the fastq.gz file we selected for this example. We will then deploy the job and come back to find our FASTQ file in the ```Data > Job Results``` section on the Deploit platform.

We will run the following command as mentioned earlier:<br>

```wget -O - https://lifebit.page.link/ftp_SRR062634_fastq_gz | gunzip -c > SRR062634.fastq```

Have it ready for copy+pasting, and let's go back to the Deploit platform.
Access the newly created pipeline that utilizes the Alpine Linux docker container (we named ours `wgetGunzipper`) by clicking:<br>

```Pipelines``` > ```My Pipelines & Tools``` > ```wgetGunzipper``` <br> 

Paste the command from above in the ```Executable``` field. Take a look at how this will look on the Deploit platform below:

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/wget_gunzipper_command.gif?raw=true">
<br><br>

You can see an overview of the final command in the bottom of the screen: 

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/final_command.PNG?raw=true">
<br><br>

Now we are ready to deploy the first of the __two jobs__ for retrieving the FastQC report.

Click on  ```Next``` on the top right of your screen. You will be redirected to the page where you will:
<br><br>

1) Select ```Project```, in which your job belongs to (we selected `fastQsee`)<br>
2) Select instance for deploying your job 

<br>

When you select both, you are ready to submit your job. Go ahead and click ```Run job```. You will be redirected to the ```Jobs``` page. Your job will be scheduled, initialized and be completed shortly. Take a look below to check how these steps should look in the Deploit platform.

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/select_project_select_instance_schedule_job.gif?raw=true">
<br><br>

After job completion, you can access the decompressed FASTQ file in the ```Data > Job Results``` section. 
We expect to find our FASTQ file in the `fastQsee` ```Project``` folder, with a filename as we defined it when retrieving it  ```SRR062634.fastq```.<br>

__Reminder:__ This is the command we submitted to __download__, __decompress__ and __rename__ the ```fastq.gz``` file:<br>

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/final_command.PNG?raw=true">
<br><br><br>

## STEP 3: Use the uncompressed FASTQ file as input to ```lifebitai/fastqc``` 

Our input file for the next and last step, the uncompressed FASTQ file is now available on the Deploit platform in the ```Data > Job Results``` section. We will use this file as input for the ```lifebitai/fastqc``` pipeline, which is essentially a dockerized version of the FastQC tool and its dependencies. In the  ```Pipelines > PUBLIC PIPELINES & TOOLS ``` section, start typing `"fastqc"` in the search bar to easily find the ```lifebitai/fastqc``` pipeline.

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/query_pips_fastqc.gif?raw=true" >
<br><br><br>

Time to set up the pipeline. Let's:
<br>

1) define input data <br> 
2) select ```Project``` that the pipeline will be associated with <br>
3) select instance (cloud resources) 

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/select_project_select_instance_schedule_job.gif?raw=true" >
<br><br>

As shown above we have selected as input data, the 1000geomes FASTQ file we fetched from the EMBL-EBI FTP server in the previous step. ```None``` other parameteres are required to run the `fastqc` pipeline. We then selected an instance (anything larger than 1 CPU would work).

<br><br><br>

### STEP 3 - Quick tip: Easily run available pipelines on Deploit
All curated pipelines included in Deploit's library, in the ```Pipelines > PUBLIC PIPELINES & TOOLS``` section, come with example parameters and data. 
Click <br> ```Try with example data & parameters``` to:
<br>
<br>

#### 1. Figure out the required flags and arguments to run the pipeline <br>
from the Deploit fields: 

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/check_parameters.gif?raw=true">
<br><br>

or from the final command field:

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/final_command_field_example_params.PNG?raw=true">
<br><br>

This way you can see how the command should look like when you customize the pipeline with your own parameters and input data. For example, as shown above we can see that the ```lifebitai/fastqc``` pipeline can be run just by typing:

<br><br>

```fastq name_of_my_fastq_file.qc``` 

<br><br>

Notice the `.fq` file format required and `None` other parameters.

<br><br>

#### 2. Take a look at output files of new pipelines 

<br><br> 

You can run with example parameters & data just to check the output files that the pipeline generates, and explore new pipelines and tools you haven't used before for your own omics data. You might discover another way you can interrogate your omics data and generate more results to inspect.


<br><br><br>

## STEP 4: Job completed! Time to inspect the FastQC html report

Once the job has been completed, you can access your results from the ```Job Page```, as shown below:

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/access_results.gif?raw=true">
<br><br>

The ```Job Page``` serves like a summary report that includes information about:

<br><br>

* ``` Pipeline and configuration```: Name of Pipeline and configuration selected for this job 
* ``` Job status```: Job progress (% complete) or if it has failed 
* ``` Resource Monitor```: __CPU__ usage, __RAM__ requirements 
* ``` Table overview```: Runtime, number of processes, total cost

<br><br>

It also works as a portal to access all the generated output files in the ```Results``` section. 
Every job is assigned a unique ```Job ID```, so that you can reference back to them or to retrieve programmatically information about the job using your private key through Deploit's restful API.

<br><br><br>

## STEP 5: Share, reproduce, re-use


### Share
You can also share your ```Job page``` and hence analysis results by creating a public sharable link from the ```Job page``` as shown below:<br>

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/make_page_public.gif?raw=true">
<br><br>

Anyone that has your public link can access your ```Job page```. Want to stop sharing? No worries! Just make the page private again and the url will lead to a cute tardigrade 404 page. <br>
Take a look below: 

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/unmake_page_public.gif?raw=true" >
<br><br><br>

### Reproduce: 
<br><br>

#### Immutable Docker digests 

In the ```Job page``` you can easily access the Docker image digest. <br>

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/image_digest.gif?raw=true">
<br><br>

Digests are unique immutable Docker container identifiers and we choose to use those to ensure that the image we use when cloning a job is always the same. Tags are mutable and they don't guarantee reproducibility. You can read more about it in the official Docker Docs page <a href="https://lifebit.page.link/DockerDocs" target="_blank"><b>here</b></a>.

<br><br>
<a href="https://lifebit.page.link/DockerDocs"  target="_blank">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/docker_digests.png?raw=true"> 
</a>
<br><br><br>

#### GitHub commits

<br><br>

If you port a pipeline from GitHub, you also have access to the GitHub commit so that you know exactly what revision you have used for running you're pipeline. Straight from the GitHub glossary  

You can access it from the ```Job Page > Pipeline and configuration> Revision``` as shown below:

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/GitHubCommit.gif?raw=true">
<br><br><br>


###  Re-use

If you have already run a ```Job``` on the Deploit platform, you can easily use the `clone` feature to revisit your pipeline. By clicking on __`clone`__ you will get a different ```Job ID``` but an automatic identical configuration set-up . You will be redirected in the job submission page.<br>

Take a look below: 

<br><br>
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/clone_job.gif?raw=true">
<br><br>


After cloning, you can easily modify the pipeline configuration as little (eg. change input file and keep all other parameters the same) or __as much__ (eg. modify everything by changing the parameter values) as you like. This helps you quickly modify and re-use pipelines. 

<br><br><br>

## Time for you to Deploit!

<br><br>
Now you are ready to give Deploit a try yourself! Use this tutorial as a guide to deploy your own analysis on the Deploit platfom. You can also download this tutorial html file (and the Rmarkdown that created it!) from the Deploit Platform using the sharable page url fro Deploit. Use the sharable url below, go to results and download the `fastQsee_tutorial.Rmd` or preview the `fastQsee_tutorial.html`:

<br><br>

<p style="text-align:center;">
<a href="https://lifebit.page.link/fastQsee_Job_Page" target="_blank"><b>The fastQsee Project Folder on Deploit</b></a>
</p>

<br><br>
<a href="https://lifebit.page.link/fastQsee_Job_Page">
<img src="https://github.com/cgpu/fastQsee_helper_repo/blob/master/images/download_fastqsee_from_deploit.gif?raw=true">
</a>
<br><br><br>


# Acknowledgements

Many thanks to <a href="https://lifebit.page.link/Phil_GitHub" target="_blank"><b>Phil Palmer</b></a> and <a href="https://lifebit.page.link/diogo_GitHub" target="_blank"><b>Diogo Silva</b></a> for reproducibility and Docker feedback.
<br><br><br><br><br><br>
